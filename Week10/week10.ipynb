{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dfs\n",
    "train_df = pd.read_csv(\"fake_train.csv\")\n",
    "test_df = pd.read_csv(\"fake_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump administration to review goal of world w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish academics to be tried in April over Ku...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Italy's new electoral law offers a mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: Trump Get His A** Handed To Him By Chr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexico president says Trump visit could have b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Trump administration to review goal of world w...      1\n",
       "1  Turkish academics to be tried in April over Ku...      1\n",
       "2  Factbox: Italy's new electoral law offers a mi...      1\n",
       "3   WATCH: Trump Get His A** Handed To Him By Chr...      0\n",
       "4  Mexico president says Trump visit could have b...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  As U.S. budget fight looms, Republicans flip t...      1\n",
       "1  U.S. military to accept transgender recruits o...      1\n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...      1\n",
       "3  FBI Russia probe helped by Australian diplomat...      1\n",
       "4  Trump wants Postal Service to charge 'much mor...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding total label\n",
    "train_df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null if any\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null if any\n",
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2\n",
    "\n",
    "1. Keeping alphabets only as numbers and other characters do not contribute directly without context\n",
    "2. Removing stopwords as it effects the abundance but not directly in word2vec, still removing to shrink the search space\n",
    "3. To lowercase as it is just modeling the topics and tagging with some numerical value\n",
    "4. Lemmatization: the core form of words are needed rather than the participle forms to find the relationships in this exercise\n",
    "5. Doing the same pre-processing to test data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence: str) -> list:\n",
    "    \"\"\"cleaning text by extracting alphabets and\n",
    "    then splitting into word list for each sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence string\n",
    "\n",
    "    Returns:\n",
    "        list: list of words.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"[A-Za-z]+\")\n",
    "    return re.findall(pattern=pattern, string=sentence)\n",
    "\n",
    "def to_lowercase(word_list: list) -> list:\n",
    "    \"\"\"case changing of all contents in each list\n",
    "    of words\n",
    "\n",
    "    Args:\n",
    "        word_list (list): list of words with alphabets only texts\n",
    "\n",
    "    Returns:\n",
    "        word_list (list): list of words with lowercase transformation\n",
    "    \"\"\"\n",
    "    return [word.lower() for word in word_list]\n",
    "\n",
    "def remove_stopwords(list_of_words: list) -> list:\n",
    "    \"\"\"removing stop words from list of words by matching\n",
    "    English stop words and extracting those out \n",
    "    \n",
    "    Args:\n",
    "        list_of_words (list): list of words with stop words\n",
    "\n",
    "    Returns:\n",
    "        list: stop word free list of words\n",
    "    \"\"\"\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "\n",
    "    return [word for word in list_of_words if word not in stopword_list]\n",
    "\n",
    "def extract_word_lemma(word_list: list) -> list:\n",
    "    \"\"\"lemmatization of words list from word of list\n",
    "    using NLTK WordNetLemmatizer class\n",
    "\n",
    "    Args:\n",
    "        word_list (list): list of string\n",
    "\n",
    "    Returns:\n",
    "        list: lemmatized list of strings\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [\n",
    "        lemmatizer.lemmatize(word, tag[0].lower())\n",
    "        if tag[0].lower() in [\"n\", \"v\", \"a\", \"r\", \"s\"]\n",
    "        else word\n",
    "        for word, tag in pos_tag(word_list)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping alphabets only\n",
    "train_df[\"cleaned_corpus\"] = train_df[\"text\"].apply(lambda text: clean_text(text) if not pd.isna(text) else \"\")\n",
    "# removing stopwords\n",
    "train_df[\"cleaned_corpus\"] = train_df[\"cleaned_corpus\"].apply(lambda word_list: remove_stopwords(word_list))\n",
    "# to lowercase\n",
    "train_df[\"cleaned_corpus\"] = train_df[\"cleaned_corpus\"].apply(lambda word_list: to_lowercase(word_list))\n",
    "# extracting lemma\n",
    "train_df[\"cleaned_corpus\"] = train_df[\"cleaned_corpus\"].apply(lambda word_list: extract_word_lemma(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping alphabets only\n",
    "test_df[\"cleaned_corpus\"] = test_df[\"text\"].apply(lambda text: clean_text(text) if not pd.isna(text) else \"\")\n",
    "# removing stopwords\n",
    "test_df[\"cleaned_corpus\"] = test_df[\"cleaned_corpus\"].apply(lambda word_list: remove_stopwords(word_list))\n",
    "# to lowercase\n",
    "test_df[\"cleaned_corpus\"] = test_df[\"cleaned_corpus\"].apply(lambda word_list: to_lowercase(word_list))\n",
    "# extracting lemma\n",
    "test_df[\"cleaned_corpus\"] = test_df[\"cleaned_corpus\"].apply(lambda word_list: extract_word_lemma(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus list initalization\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info:] Working with dataframe 1\n",
      "[Info:] Working with dataframe 2\n"
     ]
    }
   ],
   "source": [
    "# creating corpus from tagged documents\n",
    "for k, df in enumerate([train_df, test_df]):\n",
    "    print(f\"[Info:] Working with dataframe {k+1}\")\n",
    "    for i, row in df.iterrows():\n",
    "        corpus.append(\n",
    "            TaggedDocument(\n",
    "                words=row[\"cleaned_corpus\"],\n",
    "                tags=[row[\"label\"]]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info:] Corpus size:  36913\n",
      "[Info:] Total size:  36913\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(\"[Info:] Corpus size: \", len(corpus))\n",
    "print(\"[Info:] Total size: \", len(train_df)+len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating doc2vec object\n",
    "doc2vec_window_4 = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    window=4,\n",
    "    workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating vocabs\n",
    "doc2vec_window_4.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training doc2vec\n",
    "doc2vec_window_4.train(\n",
    "    corpus,\n",
    "    total_examples=doc2vec_window_4.corpus_count,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info:] Working with dataframe 1\n",
      "[Info:] Working with dataframe 2\n"
     ]
    }
   ],
   "source": [
    "# inferring vectors by passing tokens of each row\n",
    "vectors = []\n",
    "for k, df in enumerate([train_df, test_df]):\n",
    "    print(f\"[Info:] Working with dataframe {k+1}\")\n",
    "    for i, row in df.iterrows():\n",
    "        vectors.append(\n",
    "            doc2vec_window_4.infer_vector(row[\"cleaned_corpus\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check vector sizes\n",
    "vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump administration to review goal of world w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[trump, administration, review, goal, world, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish academics to be tried in April over Ku...</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkish, academic, try, april, kurdish, lette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Italy's new electoral law offers a mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[factbox, italy, new, electoral, law, offer, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: Trump Get His A** Handed To Him By Chr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, trump, get, his, a, hand, to, him, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexico president says Trump visit could have b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mexico, president, say, trump, visit, could, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Trump administration to review goal of world w...      1   \n",
       "1  Turkish academics to be tried in April over Ku...      1   \n",
       "2  Factbox: Italy's new electoral law offers a mi...      1   \n",
       "3   WATCH: Trump Get His A** Handed To Him By Chr...      0   \n",
       "4  Mexico president says Trump visit could have b...      1   \n",
       "\n",
       "                                      cleaned_corpus  \n",
       "0  [trump, administration, review, goal, world, w...  \n",
       "1  [turkish, academic, try, april, kurdish, lette...  \n",
       "2  [factbox, italy, new, electoral, law, offer, m...  \n",
       "3  [watch, trump, get, his, a, hand, to, him, by,...  \n",
       "4  [mexico, president, say, trump, visit, could, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat dataframe, train_df and then test_df\n",
    "df = pd.concat([train_df, test_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_corpus</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump administration to review goal of world w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[trump, administration, review, goal, world, w...</td>\n",
       "      <td>[-0.60876584, 0.8974504, -0.22005816, 0.385045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish academics to be tried in April over Ku...</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkish, academic, try, april, kurdish, lette...</td>\n",
       "      <td>[0.16721743, 0.9464363, -0.31198788, 0.6175166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Italy's new electoral law offers a mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[factbox, italy, new, electoral, law, offer, m...</td>\n",
       "      <td>[-0.311118, 0.9653612, -0.25668618, 0.3904911,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WATCH: Trump Get His A** Handed To Him By Chr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, trump, get, his, a, hand, to, him, by,...</td>\n",
       "      <td>[-0.7879092, 0.15529503, 0.19538662, 1.0960517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexico president says Trump visit could have b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mexico, president, say, trump, visit, could, ...</td>\n",
       "      <td>[-0.021175845, 0.5596713, -0.24676293, 0.57634...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Trump administration to review goal of world w...      1   \n",
       "1  Turkish academics to be tried in April over Ku...      1   \n",
       "2  Factbox: Italy's new electoral law offers a mi...      1   \n",
       "3   WATCH: Trump Get His A** Handed To Him By Chr...      0   \n",
       "4  Mexico president says Trump visit could have b...      1   \n",
       "\n",
       "                                      cleaned_corpus  \\\n",
       "0  [trump, administration, review, goal, world, w...   \n",
       "1  [turkish, academic, try, april, kurdish, lette...   \n",
       "2  [factbox, italy, new, electoral, law, offer, m...   \n",
       "3  [watch, trump, get, his, a, hand, to, him, by,...   \n",
       "4  [mexico, president, say, trump, visit, could, ...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-0.60876584, 0.8974504, -0.22005816, 0.385045...  \n",
       "1  [0.16721743, 0.9464363, -0.31198788, 0.6175166...  \n",
       "2  [-0.311118, 0.9653612, -0.25668618, 0.3904911,...  \n",
       "3  [-0.7879092, 0.15529503, 0.19538662, 1.0960517...  \n",
       "4  [-0.021175845, 0.5596713, -0.24676293, 0.57634...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# including vectors as separate column for each row of \n",
    "# the concatenated dataframe\n",
    "# df[\"vectors\"] = vector_list\n",
    "df[\"vectors\"] = vectors\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectors</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.60876584, 0.8974504, -0.22005816, 0.385045...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.16721743, 0.9464363, -0.31198788, 0.6175166...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.311118, 0.9653612, -0.25668618, 0.3904911,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.7879092, 0.15529503, 0.19538662, 1.0960517...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.021175845, 0.5596713, -0.24676293, 0.57634...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             vectors  label\n",
       "0  [-0.60876584, 0.8974504, -0.22005816, 0.385045...      1\n",
       "1  [0.16721743, 0.9464363, -0.31198788, 0.6175166...      1\n",
       "2  [-0.311118, 0.9653612, -0.25668618, 0.3904911,...      1\n",
       "3  [-0.7879092, 0.15529503, 0.19538662, 1.0960517...      0\n",
       "4  [-0.021175845, 0.5596713, -0.24676293, 0.57634...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construction of regression df just to isolate\n",
    "regression_df = pd.DataFrame({\"vectors\": df[\"vectors\"], \"label\": df[\"label\"]})\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training a logistic regression with default hyper params\n",
    "# inital test set size 10%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    regression_df[\"vectors\"].tolist(),\n",
    "    regression_df[\"label\"],\n",
    "    test_size=0.1\n",
    ")\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1871,   72],\n",
       "       [  52, 1697]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constructing confusion matrix\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664138678223185"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating accuracy score\n",
    "accuracy_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647527003979534"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating f1 score\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating corpus from tagged documents only in train data\n",
    "train_corpus = []\n",
    "for i, row in train_df.iterrows():\n",
    "    train_corpus.append(\n",
    "        TaggedDocument(\n",
    "            words=row[\"cleaned_corpus\"],\n",
    "            tags=[row[\"label\"]]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating doc2vec object on train corpus\n",
    "doc2vec_window_4_train = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    window=4,\n",
    "    workers=10\n",
    ")\n",
    "# initiating vocabs\n",
    "doc2vec_window_4_train.build_vocab(train_corpus)\n",
    "# training doc2vec on train set\n",
    "doc2vec_window_4_train.train(\n",
    "    train_corpus,\n",
    "    total_examples=doc2vec_window_4_train.corpus_count,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectors</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.005902393, 0.1592356, 0.07952905, 0.689933...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3238817, 0.07887071, -0.088781185, -0.16598...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.021988591, -0.0017752807, -0.070960835, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.07347778, -0.1422588, -0.05785784, 0.360505...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.14076675, 0.07505335, -0.074533395, 0.2981...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             vectors  label\n",
       "0  [-0.005902393, 0.1592356, 0.07952905, 0.689933...      1\n",
       "1  [0.3238817, 0.07887071, -0.088781185, -0.16598...      1\n",
       "2  [-0.021988591, -0.0017752807, -0.070960835, -0...      1\n",
       "3  [0.07347778, -0.1422588, -0.05785784, 0.360505...      0\n",
       "4  [-0.14076675, 0.07505335, -0.074533395, 0.2981...      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inferring vectors by passing tokens of each row\n",
    "vectors_train = []\n",
    "for i, row in train_df.iterrows():\n",
    "    vectors_train.append(\n",
    "        doc2vec_window_4_train.infer_vector(row[\"cleaned_corpus\"])\n",
    "    )\n",
    "# creating vectors column for vectors\n",
    "train_df[\"vectors\"] = vectors_train\n",
    "# regression df creation on train set\n",
    "regression_df_train = pd.DataFrame(\n",
    "    {\"vectors\": train_df[\"vectors\"], \"label\": train_df[\"label\"]}\n",
    ")\n",
    "regression_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on train set only, \n",
    "# training a logistic regression with default hyper params\n",
    "# inital test set size 10%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    regression_df_train[\"vectors\"].tolist(),\n",
    "    regression_df_train[\"label\"],\n",
    "    test_size=0.1\n",
    ")\n",
    "# intialising and training by fitting data\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[582,  10],\n",
       "       [  8, 523]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constructing confusion matrix\n",
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839715048975958"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating accuracy score\n",
    "accuracy_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830827067669173"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating f1 score\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is almost same but around 2% in hold-out training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
